2017-05-17

O cérebro humano é considerado o mais fascinante processador existente. Ele é composto por aproximadamente 10 bilhões de neurônios, que são responsáveis por todas as funções e movimentos do nosso organismo. Os neurônios estão conectados uns aos outros através de sinapses, e juntos formam uma grande rede, denominada <strong>Rede Neural</strong>, que proporciona uma fabulosa capacidade de processamento e armazenamento de informação.

Há algumas décadas, surgiu a ideia de modelar, computacionalmente, as conexões neurais do cérebro humano, com intuito de emergir comportamentos inteligentes em máquinas. Neste contexto, surgiu as Redes Neurais Artificiais (RNA's), inspiradas na própria natureza das redes de neurônios cerebrais e sinapses biológicas.

[caption id="" align="alignleft" width="350"]<img src="http://www.recantododragao.com.br/wp-content/uploads/2014/04/axons.jpg" alt="" width="350" height="181" /> Fig1. Rede neural humana: o melhor processador de informações existente[/caption]

Uma rede neural artificial é um um sistema de processamento paralelo de informações constituído pela interconexão de unidades básicas de processamento, denominadas neurônios artificiais, que tem a propensão natural para armazenar conhecimento experimental e torná-lo disponível para o uso (Haykin, 1998). Todo conhecimento adquirido pela rede se da através de um algoritmo de aprendizagem, cuja função é modificar os pesos de conexões entre os neurônios da rede, conhecidos como pesos sinápticos, de forma ordenada a fim de alcançar o mapeamento desejado.

O neurônio artificial é a menor unidade de processamento de uma rede neural, que recebe sinais de entrada e produzem sinais de saída. O modelo de neurônio mais utilizado é o <em>perceptron</em>, representado na Fig. 2, que é composto por: <em>m</em> entradas <em>(x1, ... ,xm)</em>, <em>m</em> pesos sinápticos <em>(w1, ... ,wm)</em>, uma variável de deslocamento linear <em>b</em> (do inglês: <em>bias</em>) e uma saída <em>y</em>, que é descrita por:

<img class="aligncenter" src="http://latex.codecogs.com/gif.latex?y%20%3D%20%5Ctheta%20%28%5Csum_%7Bi%3D1%7D%5E%7Bm%7D%20x_%7Bi%7Dw_%7Bi%7D%20+%20b%20%29" alt="" width="148" height="51" />

[caption id="attachment_148" align="aligncenter" width="300"]<a href="http://www.computacaointeligente.com.br/wp-content/uploads/2015/04/neuronio_r1_c1.jpg"><img class="wp-image-148 size-medium" src="http://www.computacaointeligente.com.br/wp-content/uploads/2015/04/neuronio_r1_c1-300x130.jpg" alt="" width="300" height="130" /></a> Fig 2. Modelo de neurônio artificial[/caption]

A função θ é conhecida como função de ativação ou função de transferência. Dentre as funções de ativação mais utilizadas estão a <em>sigmóide</em> e a <em>tangente hiberbólica</em>, definidas pelas equações abaixo, respectivamente:

<img class="aligncenter" src="http://latex.codecogs.com/gif.latex?%5C%5C%20%5C%5C%20%5Ctheta%20%28u%29%3D%20%5Cdfrac%7B1%7D%7B1+e%5E%7B-au%7D%7D%20%5C%5C%20%5C%5C%20%5Ctheta%20%28u%29%3D%20%5Cdfrac%7Be%5E%7Bu%7D%20-%20e%5E%7B-u%7D%7D%7Be%5E%7Bu%7D%20+%20e%5E%7B-u%7D%7D" alt="" width="125" height="88" />

A arquitetura de uma rede neural está relacionada com a maneira pela qual os neurônios da mesma estão organizados. Para isso, a rede é dividida em três tipos de camadas: a de entrada, a escondida e a de saída. As camadas de entrada e saída são intuitivas e representam o número de entradas e saídas do problema em questão. Já a escondida é a camada que fará a maior parte do processo de aprendizagem da rede. Normalmente uma rede neural possui uma camada de entrada, uma camada de saída e <em>k</em> camadas escondidas, no qual <em>k</em> é definido empiricamente e varia de acordo com o problema. Com isso forma-se uma rede de múltiplas camadas.

Redes neurais do tipo <em>Feedforward </em>(em português costumam traduzir como alimentação direta ou avante) são redes de múltiplas camadas no qual a informação só propaga em um sentido. No caso, os sinais provenientes dos neurônios de uma camada só podem estimular os neurônios da camada seguinte, não existindo realimentação. A Fig. 3 mostra uma rede neural de múltiplas camadas do tipo <em>Feedforward</em>, com uma camada de entrada, com <em>m</em> entradas, <em>k</em> camadas escondidas e uma camada de saída com <em>n</em> saídas.

[caption id="attachment_488" align="aligncenter" width="433"]<a href="http://www.computacaointeligente.com.br/wp-content/uploads/2017/04/redeFeed.png"><img class="wp-image-488" src="http://www.computacaointeligente.com.br/wp-content/uploads/2017/04/redeFeed.png" alt="redeFeed" width="433" height="289" /></a> Fig 3: exemplo de rede neural artificial do tipo feedforward com k camadas escondidas[/caption]

Após projetada a arquitetura da rede (determinar número de entradas, saídas, camadas escondidas e número de neurônios), é necessário um algoritmo de treinamento para realizar a aprendizagem da mesma. No processo de treinamento a rede 'aprende' através de exemplos que relacionam as entradas e saídas do problema a ser solucionado. Essa abordagem é conhecida como aprendizado supervisionado. Dentre os algoritmos conhecidos, para solucionar esse tipo de problema, o mais utilizado é o <em>backpropagation</em> (Rumelhart, Hinton, e Willians, 1986). A ideia do algoritmo é estimar os valores dos pesos e <em>bias</em> minimizando o erro entre a entrada e a saída desejada usando o gradiente descendente. O erro E cometido pela rede é calculado por:

<img class="aligncenter" src="http://latex.codecogs.com/gif.latex?E%20%3D%20%5Cdfrac%7B1%7D%7B2%7D%20%5Csum_%7Bi%3D1%7D%5E%7Bp%7D%20%5Csum_%7Bj%3D1%7D%5E%7Bn%7D%20%28d_j%5Ei%20-%20y_j%5Ei%29%5E2" alt="" width="184" height="54" />

no qual, <em>p</em> é o número exemplos a ser utilizados no treinamento, <em>n</em> é o número de saídas da rede e, finalmente, <em>d</em> e <em>y</em> são as saídas desejadas e obtidas, respectivamente, para a entrada em curso.
A regra de atualização de cada peso sináptico da rede é calculado pela seguinte equação:

<img class="aligncenter" src="http://latex.codecogs.com/gif.latex?W%20%3D%20W%20+%20%5CDelta%20W%20%5Ctherefore%20%5CDelta%20W%20%3D%20-%20%5Calpha%20%5Cdfrac%7B%5Cpartial%20E%7D%7B%5Cpartial%20W%7D" alt="" width="257" height="39" />

onde, α é conhecido como taxa de aprendizado, que, resumidamente, indica o 'tamanho do passo' do gradiente rumo a minimização. O sinal negativo indica a busca por uma alteração no peso que reduza <em>E</em>.

&nbsp;
<h3>Utilizando RNA no MATLAB</h3>
Implementar um RNA do zero não é uma tarefa tão complicada, mas sugiro que utilize uma linguagem que forneça ferramenta para manipulação de matrizes. Alias, na minha visão, implementar um algoritmo é primordial para uma melhor compreensão do mesmo (eu mesmo já implementei minha RNA lá nos primordios rs). Todavia, se o intuito é obter resultados mais rápido com uma ferramenta já validada, sugiro fortemente a <em>toolbox</em> do MATLAB para RNA, que é um ambiente todo preparado para prototipação com redes neurais.Se você está iniciando ou não conhece a <em>toolbox </em>sugiro a leitura do tutorial abaixo que mostra o básico de como utilizar a redes neurais no MATLAB<em>. </em>

Por fim, deixo um código de uma predição de uma série temporal utilizando a <em>toolbox. </em>A série representa a demanda mensal de energia na Austrália, entre determinado período de tempo, e a rede neural é utilizado como preditor da mesma. É utilizado 70% da série para treinar a rede e 30% para executar e checar se o resultado que a rede obteve é compatível com a realidade. Com o código sugiro que varie o número de neurônios, camadas e função de ativação para observar a influência de cada um deles no resultado final. Do mais, faça bom uso =)

<strong>Links</strong>

<a href="https://www.dropbox.com/s/n364ibn2xous6ua/Tutorial%20RNA%20MATLAB.pdf?dl=0" target="_blank">Tutorial de RNA utilizando MATLAB</a>

<a href="https://www.dropbox.com/s/wbhbfwv0tytotqu/FFnet.rar?dl=0" target="_blank">Predição de uma série temporal com RNA</a>

&nbsp;
<h3>Referências</h3>
[1] Haykin, S., Neural Networks: A Comprehensive Foundation, Prentice Hall, 2º edition, 1998

[2] Rumelhart, D. E., Hinton, G. E. e Willians, R. J. Learning representations by backpropagating errors, Nature, v. 323, p. 533-536, 1986.

&nbsp;
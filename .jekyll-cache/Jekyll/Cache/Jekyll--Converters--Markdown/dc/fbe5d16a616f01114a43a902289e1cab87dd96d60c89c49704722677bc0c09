I"€(<h1 id="introdu√ß√£o">Introdu√ß√£o</h1>

<p>O algoritmo gen√©tico (do ingl√™s: <em>genetic algorithm</em> - GA) √© um m√©todo evolutivo de otimiza√ß√£o introduzido por John Holland em 1975 <a href="#holland">[1]</a> e mais tarde foi popularizado por David Goldberg <a href="#goldberg">[2]</a>. O GA se inspira nos princ√≠pios da teoria da sele√ß√£o natural, proposta por Charles Darwin, na qual somente os indiv√≠duos mais aptos sobrevivem para uma pr√≥xima gera√ß√£o. Como o GA √© um algoritmo de otimiza√ß√£o, √© necess√°rio entender o que √© um <a href="/artigos/o-problema-de-otimizacao/">problema de otimiza√ß√£o</a>. Caso n√£o seja familiar com assunto, sugiro fortemente que acesse o nosso post o leia antes de continuar. Caso voc√™ j√° domine este assunto, siga em frente.</p>

<p>Assim como o <a href="/algoritmos/otimizacao-por-enxame-de-particulas/">PSO</a> e o <a href="/algoritmos/o-algoritmo-evolucao-diferencial/">DE</a>, j√° apresentados neste blog, o GA tamb√©m utiliza uma popula√ß√£o de indiv√≠duos (tamb√©m chamada de cromossomos). Essa popula√ß√£o ser√° submetida a 3 operadores: <strong>sele√ß√£o</strong>, <strong>crossover</strong> (ou cruzamento) e <strong>muta√ß√£o</strong>. Aplicando estes operadores de maneira iterativa, ao fim de um crit√©rio de parada pr√©-estabelecido, o algoritmo entrega a otimiza√ß√£o desejada (ou algo pr√≥ximo dela). Neste ponto, se voc√™ leu o post na qual discutimos sobre o DE, j√° deve ter percebido que ambos os algoritmos s√£o muito semelhantes.</p>

<h1 id="teoria-da-sele√ß√£o-natural">Teoria da sele√ß√£o natural</h1>

<p>Para entender a ideia por tr√°s do GA, vamos fazer uma analogia com a teoria da sele√ß√£o natural, de onde o algoritmo foi inspirado. Imagine uma fam√≠lia com pai, m√£e e filho. O filho √© gerado a partir da combina√ß√£o dos genes de seus pais. Agora imagine milhares de pessoas se relacionando, gerando filhos (ou seja, uma popula√ß√£o) e transmitindo seus genes (essas seriam as etapas de cruzamento e muta√ß√£o do algoritmo). De acordo com Darwin, somente os indiv√≠duos mais aptos sobrevivem para perpetuar a esp√©cie. Isso ocorre por conta de uma sele√ß√£o, que neste caso, √© natural. Da popula√ß√£o de filhos, os genes mais aptos ser√£o transmitidos para as pr√≥ximas gera√ß√µes de popula√ß√£o. Por√©m, a sele√ß√£o natural leva muito tempo para evoluir nossa esp√©cie (n√£o entrarei nas discuss√µes biol√≥gicas, filos√≥ficas e afins). A ideia do GA √© simular esse procedimento para otimizar algum problema. Um dos v√≠deos mais legais relacionados a <a href="https://www.youtube.com/watch?v=N-SrvGfwiTg">sele√ß√£o natural √© da s√©rie quer que desenhe</a>. Caso tenha interesse, sugiro fortemente que assista, vale muito a pena.</p>

<h1 id="o-algoritmo-ga">O algoritmo GA</h1>

<p>Bom, dado a breve introdu√ß√£o, vamos ao algoritmo de fato. O GA pode ser implementado para n√∫meros¬†bin√°rios ou cont√≠nuos. A vers√£o apresentada aqui, ser√° a cont√≠nua, todavia vamos apenas ilustrar a ideia bin√°ria, pois a mesma √© bem interessante quando comparada¬†com o processo da evolu√ß√£o natural.</p>

<h2 id="tipos-de-popula√ß√µes">Tipos de popula√ß√µes</h2>

<p>Na Figura 1a √© apresentada uma popula√ß√£o de \(N\) indiv√≠duos ou cromossomos. Perceba que cada indiv√≠duo √© formado por uma cadeia de bits. Neste caso √© interessante a nomenclatura cromossomos, pois cada cromossomo √© formado por uma cadeia de genes, ou seja, cada gene √© representado por 1 bit. Na Figura 1b √© representada outra popula√ß√£o, agora por n√∫meros reais, na qual cada gene √© uma dimens√£o. Obviamente trabalhar com a combina√ß√£o de bits √© mais trabalhoso do que com n√∫meros reais.</p>

<figure style="width: 490px; height: 250px;" class="align-center">
  
  <img src="http://0.0.0.0:4000/assets/img/posts/GA/populacoes.png" alt="" />

  <figcaption style="text-align: center;">
   Figura 1: exemplo de popula√ß√µes do GA
  </figcaption>

</figure>

<h2 id="opera√ß√µes-do-ga">Opera√ß√µes do GA</h2>

<p>Agora vamos as opera√ß√µes do algoritmo para valores reais. O primeiro passo a ser tomado √© gerar uma popula√ß√£o aleat√≥ria de tamanho \(N\). Chamaremos essa popula√ß√£o de \(pop_p\) (popula√ß√£o principal). Se o tamanho do espa√ßo de busca for conhecido, gere os valores por meio de uma distribui√ß√£o de probabilidade uniforme. Caso contr√°rio, gere de uma distribui√ß√£o normal. O tamanho da popula√ß√£o utilizado √© escolhido de maneira emp√≠rica. Normalmente se utiliza \(N\) igual a 10 vezes a dimens√£o do problema a ser otimizado, ou seja, se a fun√ß√£o objetivo for \(f(x,y,z)\), estamos otimizando um problema de 3 dimens√µes (novamente, se voc√™ n√£o sabe o que √© uma fun√ß√£o objetivo, acesse o nosso post sobre o problema de otimiza√ß√£o linkado na introdu√ß√£o).</p>

<h3 id="sele√ß√£o">Sele√ß√£o</h3>

<p>Gerada a popula√ß√£o, o primeiro operador a ser utilizado √© a <strong>sele√ß√£o</strong>. Nesta etapa √© gerada uma popula√ß√£o intermedi√°ria \(pop_i\), tamb√©m de tamanho \(N\), a partir da \(pop_p\), da seguinte forma:</p>

<ol>
  <li>S√£o sorteados dois indiv√≠duos pertencentes a¬†\(pop_p\) e s√£o comparados por meio da fun√ß√£o objetivo¬†previamente determinada. O individuo mais apto, ou seja, com melhor valor na fun√ß√£o objetivo segue adiante para a \(pop_i\).</li>
  <li>O passo anterior √© repetido at√© que as¬†\(N\) posi√ß√µes de¬†\(pop_i\) sejam preenchidas pelos melhores indiv√≠duos.</li>
</ol>

<h3 id="crossover">Crossover</h3>

<p>O pr√≥ximo operador a ser realizado √© o <strong>crossover</strong>. Nesta etapa √© realizado o cruzamento entre indiv√≠duos com intuito de gerar novos indiv√≠duos. Se fosse na vers√£o bin√°ria, os bits de dois indiv√≠duos seriam cruzados. Como esta √© uma vers√£o com n√∫meros reais, o cruzamento √© realizado por meio de uma combina√ß√£o linear de dois indiv√≠duos da seguinte forma:</p>

<ol>
  <li>Primeiramente √© determinada uma taxa de crossover. Essa taxa indica a probabilidade de dois indiv√≠duos serem cruzados, portanto nem todos os indiv√≠duos ser√£o cruzados. Normalmente, valores em torno de 70% s√£o boas escolhas. Essa taxa ajuda na diversidade da popula√ß√£o. E diversidade, significa uma menor suscetibilidade a m√≠nimos ou m√°ximos locais.</li>
  <li>Em seguida, s√£o sorteados dois indiv√≠duos \(pop_i\), chamaremos de¬†\(c_1\) e¬†\(c_2\). Por meio de uma vari√°vel aleat√≥ria, verificamos se a taxa de crossover √© satisfeita, se sim √© realizado a opera√ß√£o. O crossover apresentado aqui vai gerar dois novos indiv√≠duos, \(p_1\) e¬†\(p_2\), da seguinte forma:</li>
</ol>

<p>\(p_1 = \beta c_1 + (1-\beta)c_2 
  \tag{1}\)
\(p_2 = (1-\beta) c_1 + \beta c_2 
  \tag{2}\)</p>

<p>Sendo \(\beta\) uma constante gerada a partir de uma distribui√ß√£o normal com m√©dia 1 e desvio padr√£o 0. Os indiv√≠duos¬†\(p_1\) e¬†\(p_2\) ser√£o alocados em uma nova popula√ß√£o intermedi√°ria \(pop_{ii}\).</p>

<ol>
  <li>Caso a taxa de crossover n√£o seja atendida, ou seja, \(c_1\) e¬†\(c_2\) ca√≠ram nos 30% que n√£o ir√£o sofrer crossover, os mesmos s√£o transmitidos diretamente para \(pop_{ii}\), isto √©,¬†\(p_1 = c_1\) e¬†\(p_2 = c_2\).</li>
</ol>

<p>Obviamente¬†\(pop_{ii}\) ter√° o mesmo tamanho \(N\) das demais e essa etapa √© repetida at√© que todos os indiv√≠duos de¬†\(pop_{ii}\) sejam determinados.</p>

<h3 id="muta√ß√£o">Muta√ß√£o</h3>

<p>Realizado o crossover, o pr√≥ximo operador √© a <strong>muta√ß√£o</strong>. Este operador tamb√©m auxilia na diversidade e nada mais √© do que a inser√ß√£o de um ru√≠do alguns indiv√≠duos da popula√ß√£o \(pop_{ii}\). Na vers√£o bin√°ria, seria nada mais nada menos do que alterar o valor de 1 ou 2 bits. Portanto, assim como no crossover, teremos uma taxa de muta√ß√£o. Aqui, um valor de 10% j√° √© suficiente. Com isso, apenas uma pequena parcela da popula√ß√£o vai ser mutada. Sendo \(m_1\) um indiv√≠duo pertencente ao conjunto de 10% a ser mutado, fazemos:</p>

<p>\(m_1 = m_1 \alpha
  \tag{3}\)
Sendo¬†\(\alpha\) um ru√≠do obtido por uma distribui√ß√£o normal de m√©dia 0 e desvio padr√£o 1.</p>

<p>Bom, realizado todos os operadores, neste ponto temos a \(pop_p\), que √© a nossa primeira gera√ß√£o, a \(pop_{i}\) e a \(pop_{ii}\). Agora o algoritmo √© iniciado novamente com o operador de sele√ß√£o entre a¬†\(pop_p\) e a¬†\(pop_{ii}\). Com isso, cada itera√ß√£o do algoritmo vai selecionar os indiv√≠duos mais aptos para seguir para as pr√≥ximas¬†gera√ß√µes como mostra o fluxograma da Figura 2. O algoritmo s√≥ para quando um crit√©rio de parada for alcan√ßado. Esse crit√©rio pode ser o n√∫mero de itera√ß√µes, erro m√≠nimo ou converg√™ncia da popula√ß√£o, voc√™ escolhe de acordo com o problema que esta trabalhando.</p>

<figure style="width: 490px; height: 280px;" class="align-center">
  
  <img src="http://0.0.0.0:4000/assets/img/posts/GA/fluxograma.png" alt="" />

  <figcaption style="text-align: center;">
   Figura 2: Fluxograma do algoritmo GA
  </figcaption>

</figure>

<h1 id="c√≥digo-do-algoritmo">C√≥digo do algoritmo</h1>

<p>Como de praxe, <a href="https://github.com/paaatcha/Otimizacao/tree/master/GA">deixo uma implementa√ß√£o da vers√£o discutida neste post em MATLAB</a>. Antes de encerrar, deixo claro que existem diversas outras vers√µes e altera√ß√µes no GA e a mostrada aqui √© apenas uma delas. Perceba que as constantes a ser definidas, como taxa de aprendizagem e de muta√ß√£o, interferem na converg√™ncia do seu algoritmo. Esses valores podem variar de problema para problema e por conta disso existem outras abordagem para se realizar crossover e muta√ß√£o. Como todo m√©todo heur√≠stico, ele n√£o soluciona todos os problemas e seus par√¢metros afetam no desempenho final. Mas nessa altura¬†j√° apresentamos 3 algoritmos evolutivos bastante utilizados atualmente, o DE, PSO e agora o GA. Voc√™ tem op√ß√£o de escolher aquele que se d√° melhor no seu problema. Em um pr√≥ximo post podemos debater sobre uma outra heur√≠stica inspirada na natureza, a col√¥nia de formigas. Para mais conceitos relacionados ao GA, como por exemplo o elitismo, sugiro a leitura <a href="http://www.dca.ufrn.br/~estefane/metaheuristicas/ag.pdf">deste cap√≠tulo de livro</a> em portugu√™s e muito bem explicado.</p>

<h1 id="refer√™ncias">Refer√™ncias</h1>

<p><a name="holland">[1]</a> Holland , J. H. (1975). Adaptation in Natural an d Artificial¬†Systems. MIT Press.</p>

<p><a name="goldberg">[2]</a> Goldberg, D. E. (1989). Genetic algorithms in search optimization , and machine learning. Addison-Wesley.</p>
:ET